<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>http://example.com</id>
    <title>Chen • Posts by &#34;glm&#34; tag</title>
    <link href="http://example.com" />
    <updated>2024-02-11T11:26:02.000Z</updated>
    <category term="Java" />
    <category term="Vue3" />
    <category term="GLM" />
    <category term="AI_Boot" />
    <category term="dp" />
    <category term="git" />
    <category term="位运算" />
    <category term="分类讨论" />
    <category term="redis" />
    <category term="lunix" />
    <category term="vue3" />
    <category term="机器学习" />
    <category term="LLM" />
    <category term="AI" />
    <category term="Vue.js" />
    <category term="微信小程序" />
    <category term="工作总结" />
    <category term="面试" />
    <category term="chatgpt" />
    <category term="设计模式" />
    <entry>
        <id>http://example.com/2024/02/11/Long-term-Memory/</id>
        <title>Long-term Memory-机器学习01</title>
        <link rel="alternate" href="http://example.com/2024/02/11/Long-term-Memory/"/>
        <content type="html">&lt;p&gt;想了解一下如何实现 GLM 的长记忆，以实现像 neuro 那样的长记忆功能。&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly95dWxsZXlpLm1lZGl1bS5jb20vbGFyZ2UtbGFuZ3VhZ2UtbW9kZWxzLWxsbS13aXRoLWxvbmctdGVybS1tZW1vcnktYWR2YW5jZW1lbnRzLWFuZC1vcHBvcnR1bml0aWVzLWluLWdlbmFpLWZjYzM1OTBmMWMwZQ==&#34;&gt;AI has a long-term memory problem (how to make neural networks less forgetful)&lt;/span&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;

“虽然像OpenAI的GPT这样的AI模型被训练了数十亿条数据，但它们不会记住你向它们展示的任何东西，甚至不会记住它们向你返回的任何东西，”Pinecone的创始人兼首席执行官Edo Liberty说道。“AI模型是无状态的。它们没有记忆。”

显然，“如果你无法回忆起任何东西，记忆就是无用的，”Liberty说。

在生成AI上下文和范围的局限性
今天许多领先的AI系统都是循环神经网络（RNNs）。这种深度学习方法使用过去的信息来提高对当前和未来输入的性能。其中最常用的之一是长短期记忆（LSTM）模型。

这些模型可以处理顺序信息，并保留一定数量的先前输入的上下文以处理下一个输入，CELUS战略发展合伙人兼联合创始人André Alcalde解释道。

“你可以考虑在处理句子中的单词时，这对你有多有用，”他说道。

例如，你可能有些单词是从先前的单词中引用的，所以这个模型能够保持对有限数量的输入的理解。

但这是关于LSTM模型的关键词：它们是有限的。

简单来说，“神经网络通常是健忘的，”Gartner分析师Erick Brethenoux说道。

他们“记住”了以前训练会话中的信息，并在短时间内将其考虑在内，他说。当新的训练信息进入时，模型将识别它之前见过和未见过的内容，并利用它来适应和修改。

但是，如果它看到了某些东西，然后在下一个会话中没有看到它——或者在那之后的会话中也没有看到它——模型将忘记该信息。在某种意义上，模型正在考虑：“在[当前会话]之前要记住多少个会话？”

Alcalde还指出，LSTM——以及RNNs一般——在实际应用中可能会遇到一些问题，比如训练过程中的指数（或消失）梯度、长时间的训练期和计算内存效率低下。

“要将少量数据存储在神经网络内存中，您可能需要训练大量参数，”他解释道。

更长期的AI记忆模型
Alcalde表示，长期记忆模型可以通过使用注意力增强的LSTM或具有注意力机制的新的神经网络架构来解决这些问题。这使得模型能够更好地关注重要的上下文信息，并将其视为更重要的信息。

因此，长期记忆能够更长时间地保留上下文信息，并以更节省内存的方式进行操作，从而节省计算资源，他说。这为语言模型和翻译任务提供了更好的性能，因为它们可以更好地理解正在处理的文本的上下文。

“就像人类保持长期记忆一样，[模型]可以捕获并保留几个月甚至几年的上下文，”Alcalde说道。

为了提高这种能力，例如，一组研究人员最近提出了他们所谓的“主动长期记忆网络”。他们将其描述为“一种能够在学习新知识的同时保持先前学习到的感官输入和行为输出之间关联的序列多任务深度学习模型”。

他们写道，“在人工神经网络中进行持续学习时，当顺序学习不同任务时会出现干扰和遗忘。”

增强AI记忆的矢量数据库的力量
提高AI记忆的另一种工具是矢量数据库。

正如Pinecone的Liberty所解释的，AI应用依赖于理解自然语言或图像等输入的模型。就像大脑使用化学或电神经信号传递信息一样，AI模型将它们对您展示的任何东西的理解编码为称为矢量嵌入的数字格式。

但是，他说，传统的关系数据库不设计存储和搜索矢量嵌入；AI模型需要一个专门的数据库——矢量数据库——它允许开发人员搜索“这些记忆”以找到最相关的内容，Liberty说。

矢量数据库存储大量的嵌入和相关元数据，例如标签或原始用户输入。然后，它使用算

法对这些嵌入进行索引以进行快速检索。然后，当给定一个查询（也是嵌入的形式）时，它会迅速返回最相关的结果。

“这其中的美妙之处在于搜索是通过含义而不是精确匹配完成的，因此您不需要在数据库中有任何与查询完全匹配的内容才能获得有用的答案，”Liberty说。

应用含义和上下文
Liberty表示，矢量数据库试图解决的基本问题有两个。第一个是搜索应用中缺乏意义。他指出，几十年来，工具一直依赖于将查询中的关键字与数据库中的关键字匹配。

他描述的第二个问题——他将其描述为“最近的但更痛苦的”问题，因为它阻止组织实施像ChatGPT这样的高级工具——是缺乏上下文。

“ChatGPT之类的解决方案可以解释和生成语言，但它生成的答案并不总是正确的，”他说道。这是一种被称为“幻觉”的现象。

矢量数据库可以通过让工程师构建应用程序，该应用程序搜索嵌入而不是原始文本来解决搜索应用程序中缺乏意义的问题。这种语义搜索可以产生显著更好的结果，Liberty说。

他说：“在搜索应用程序或推荐系统中，这意味着更满意的用户。”“在安全系统中，这意味着更好地检测威胁。”

与此同时，矢量数据库通过让工程师存储和发现相关上下文，并将其与原始输入/问题一起提供给AI模型来解决缺乏上下文的问题。然后，AI模型将基于其对语言的理解以及“超相关”信息生成对问题的答案。

“AI总是会给出答案，但不总是正确的，”他说。“当您将AI模型与用于长期记忆的矢量数据库相结合时，它会给出正确的答案。”

人类化行为——而不是人类的替代品
最终，长期记忆可以推动AI模型朝着更像人类行为的学习路径发展，Alcalde说。

例如，它们可以从自己的互动中学习；记住并仅应用“消耗”的书籍、新闻、音频和视频中的重要信息块；并且具有参考这些内容的能力。

但是，Brethenoux说，前进的道路应该是具有“混合学习能力”的人与机器结合。

Gartner提出了一个高级概念，称为“复合AI”或“混合AI”。这是“将不同的AI技术结合应用以提高学习效率，扩展知识表示水平，并最终以更有效的方式解决更广泛的业务问题。”

Brethenoux指出，自然，人类有长期记忆，并且我们的大脑利用抽象、感知和上下文来做出决策。正如他所说，机器应该给我们提供一些我们可以解释和行动的东西，以共生的方式。

“我希望我们不仅仅是为了自动化事物，也不仅仅是将事物呈现给人类，而是要找到更好的方法来增强智能，”他说。
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;[Large Language Models (LLM) with Long-Term Memory: Advancements and Opportunities in GenAI Applications](&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly93d3cuc2R4Y2VudHJhbC5jb20vYXJ0aWNsZXMvYW5hbHlzaXMvYWktaGFzLWEtbG9uZy10ZXJtLW1lbW9yeS1wcm9ibGVtLWhvdy10by1tYWtlLW5ldXJhbC1uZXR3b3Jrcy1sZXNzLWZvcmdldGZ1bC8yMDIzLzAzLw==&#34;&gt;AI has a long-term memory problem (how to make neural networks less forgetful) - SDxCentral&lt;/span&gt;)&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;导论
大型语言模型（LLMs）是在大量文本库上训练的参数众多的先进机器学习模型。从技术角度来看，语言建模（LM）是推动机器语言智能进步的关键技术。LM的主要目标是开发能够准确估计生成单词序列概率的模型，从而便于估计与未来标记相关或不存在的概率。

自然语言处理及相关学科的最新发展得益于大型语言模型（LLMs），如ChatGPT。研究表明，当这些模型达到一定规模时，它们会表现出新兴行为，例如具有“推理”能力。通过结合“思维链”方法，即推理示例或简单提示如“我们逐步思考”，这些模型可以通过明确的逻辑步骤回答问题。

一个LLMs可以处理的例子是：“所有鲸鱼都是哺乳动物，所有哺乳动物都有肾脏；因此，所有鲸鱼都有肾脏。”这个特定的例子在研究界引起了极大的兴奋。之所以如此激动，是因为推理的能力被认为是人类智能的基本特征，而目前的人工智能系统往往被认为缺乏这种能力。

尽管大型语言模型（LLMs）在特定推理任务上表现出色，但它们的通用推理能力以及它们可以参与推理过程的程度仍然存在争议。这种不确定性引发了研究界的持续辩论和不同观点。例如，有人说LLMs是“足够的零-shot推理者”，而其他作者得出的结论是“LLMs在日常规划/推理任务上仍有很长的路要走，这对人类来说并不构成挑战”。

在本文中，我们开始探讨记忆在推动LLMs、一些新兴架构以及它们应用的机会中的作用。后续文章将更多地涵盖实现细节和不同方法与设计模式的具体内容。

带有长期记忆的LLMs
LLMs建立在一种称为Transformer模型的深度学习架构上。Transformer模型利用自注意机制来确定文本序列中单词或元素之间的关系。这一基础及相关发展使得模型能够更好地理解和生成具有更大上下文和连贯性的文本。

为了提高LLMs的能力，研究人员考虑将长期记忆机制纳入这些模型。长期记忆允许模型在较长时间内存储信息，并在开发响应时利用这些信息。目前有两种主要方式可以将长期记忆纳入其中。

LLMs可以纳入长期记忆的一种方式是利用额外的记忆组件，例如第三方数据库，包括向量数据库或（知识）图数据库。这些组件存储事实数据或嵌入，模型可以访问并用于生成文本。通过访问这些外部记忆，LLMs可以提供更精确和准确的响应。

另一种方式是将记忆纳入模型本身。例如，模型可以包括一个内部记忆模块（例如索引、修改的注意机制等），在文本处理过程中存储相关数据。这种内部记忆可以被修改和访问，以影响模型的行为。通过在实际模型架构中使用长期记忆，LLMs可以展示更一致的行为，并针对给定上下文创建适当的响应。

架构设计考虑因素:
开发具有长期记忆的LLMs时必须考虑几个架构因素。一些关键考虑因素包括：

存储：模型的内存应该足够大，可以存储和检索相关信息。内存组件的大小和架构必须设计为容纳预期长期数据量。
存储更新：模型应该包括机制，以对新输入或数据进行长期记忆的修订。这确保了记忆的及时更新，并与当前上下文相关。
记忆检索：模型需要有效的访问和检索机制，用于从长期记忆中检索信息。这个检索过程必须快速而准确，以使模型能够在文本生成过程中利用存储的信息而不会造成过多的延迟。这在使用外部记忆组件的方法中尤为重要，比如第三方数据库。
与注意机制结合：模型的长期记忆应该与自注意机制结合。这使得模型能够在文本生成过程中关注记忆的相关部分，并根据存储的数据做出明智的决策。
训练和选择：训练具有长期记忆的LLMs需要对记忆在训练过程中如何更新和利用有透彻的理解。为了确保有效地学习和利用存储的数据，必须采用健壮的选择技术来考虑记忆组件。
为此，研究界出现了一些新的新兴架构，试图考虑这些设计考虑因素，同时改进成

本和长期记忆效率。一个例子，如下图所示，是添加一个解耦缓存层，在训练过程中保持新鲜，以补充预训练模型。

另一个例子如下图所示，是“Hyena Hierarchy”，该架构试图通过在新的稠密、无注意力架构中使用亚二次运算符来打破注意力机制的二次障碍（导致缩放成本和计算时间）。

使用来自Poli等人（2023）的Hyena Hierarchy的示例架构

这些新的范式以及研究和开发社区中出现的其他范式将在未来的文章中更详细地探讨。

GenAI应用的进展和机会
基于LLM的GenAI应用的发展为许多领域带来了新的机会。随着模型在理解和记忆扩展上变得越来越熟练，它们可以在越来越复杂和动态的情况下得到利用。

LLMs的进展
提高文本生成中的上下文理解和连贯性
GenAI应用程序理解和生成具有增强上下文理解和连贯性的文本的能力是它们的重要优势之一。现代LLMs，如GPT-3.5及以上版本，已经在大量数据上进行了训练，可能会产生更恰当和与上下文相关的响应。这种改进使得跨多个应用程序进行更有意义和精确的交互成为可能。这在长期记忆机制的改进方面进一步加强，涵盖了以下领域。

提高生成响应的准确性和特异性：
将LLMs调整到获得特定领域专业知识的能力是GenAI应用程序的主要优势之一。这超越了仅仅使用现有通用LLMs的“导言”或提示工程化。通过向模型引入大量特定领域的数据并相应地调整其参数，我们可以训练它生成表现出对话题的深刻理解的响应。这种专业化使得模型能够提供更精确和与上下文相关的数据。

此外，通过使用精细调整的LLMs，GenAI应用在信息检索方面表现出色。通过整合长期记忆机制，这些模型可以以更高的精度和相关性检索信息，从而使模型能够向用户查询提供更准确的结果。

一致的行为和减少LLMs中的偏见：
确保LLMs的一致性，减少LLMs中的幻觉和消除LLMs中的偏见，是具有巨大挑战的。通过在LLMs中利用更好的长期记忆机制，我们可以潜在地改善以下领域的偏见：

减少偏见：AI模型从数据中获取知识。如果训练数据中包含偏见，模型也会展现出相同的偏见。因此，关键是精心策划一个平衡和多样化的训练数据集。这需要精确的数据选择和评估，以减少内在和显性偏见。更好的长期记忆可以提高输出的质量，减少幻觉并可能减少有偏见的输出。

公平评估：实施和监测公正度指标可以帮助量化偏见。这些指标可以作为LLMs行为的指导原则。这其中一部分还涉及到审视LLMs在用户互动层面的输入（提示）和输出（响应）。在这方面，具有外部长期记忆机制也可能会有所帮助。在整个过程中进行定期审计和评估是识别和纠正AI系统中任何偏见的重要环节。

算法透明性：大多数LLMs在决策过程中仍然非常不透明。虽然有解释性AI技术可以帮助识别内在偏见，揭示模型是如何做出决策的，但是新兴模型架构中的记忆机制也有可能提供机会，使模型更加透明。例如，可以冻结或更新模型的某些部分或其运行的长期记忆的技术可能使模型保持最新，但也确保其符合“被遗忘权”等法规而无需重新训练。

机会:
生成AI是人工智能的一个子领域，其重点是开发模型和系统以生成新的独特内容。与传统的人工智能系统相比，传统AI系统旨在识别和分类现有数据，而生成AI旨在生成新的数据，模仿其所接触的训练数据的趋势和特征。在LLMs中加强记忆功能可以显著影响以下领域：

内容创作：AI在生成书面内容方面已经取得了显著进展，包括诗歌、新闻文章和技术论文。例如，企业可以使用AI生成营销文案或提供内容建议，从而极大地减少创建和修改内容的时间。此外，生成AI模型使用生成对抗网络（GANs）、变分自动编码器（VAEs）和R

NN等方法来生成新的内容，如图片、视频、文本和音乐。这些模型发现了训练数据的基本模式和框架，然后利用这些信息生成具有类似特征的新样本。更长的记忆时间可以帮助基于更长的上下文演变内容，并参考以前的陈述或作品中的关键要素。

个性化体验：无论是通过生成个性化购买体验还是在教育中创建独特的学习路径，生成AI都有潜力个性化我们日常生活的许多方面。改进的记忆功能将提供更好的个性化能力，可以考虑更长时间的偏好。

药物发现：生成AI已经用于预测分子的潜在属性，并在药物发现中生成新的潜在药物候选物。这已经被证明可以显著加速药物发现和开发过程。更好的长期记忆可以通过包含更多关于每种分子或药物候选物的上下文信息，进一步提高这些应用的潜力。

结论
尽管有令人兴奋的发展和机会，但仍然存在重大挑战。训练这些先进LLMs的计算复杂性很高，它们的复杂性使得理解和控制它们变得更加困难。研究人员仍在探索如何有效地处理这些权衡。这个讨论的一个关键部分是LLMs和GenAI更广泛的长期记忆的作用。

对这些先进的AI模型的伦理影响的关注不断增长。仍然存在未解决的隐私问题，特别是考虑到模型可以记住信息很长时间。至关重要的是，这些模型是否会记住并延续有害或有偏见的行为。

研究人员、开发人员、监管机构和最终用户必须合作解决这些挑战。为了负责任地挖掘基于LLM的GenAI应用的每一种潜力，有必要开发新的方法来理解模型、AI使用的伦理标准以及更有效的隐私保护方法。

总之，基于记忆和上下文的GenAI应用的快速发展代表了人工智能发展的重要里程碑。随着我们继续挑战AI可以回忆、推理和识别的界限，人类与人工智能任务之间的界限变得越来越模糊。LLMs的发展为各行各业提供了有趣的机会，但也带来了新的挑战。随着我们继续发展人工智能，前方的道路既令人兴奋又充满潜力。
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;上篇文章内的配图&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;0fb7O_linBXjDTysw.png&#34; alt=&#34;img&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Example architecture with augmented memory mechanism from&lt;/em&gt; &lt;a href=&#34;https://arxiv.org/pdf/2306.07174.pdf&#34;&gt;&lt;em&gt;Wang et al. (2023)&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;0YJ9EjdKTiBi6ox6q.png&#34; alt=&#34;img&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Example architecture using Hyena Hierarchy from&lt;/em&gt; &lt;a href=&#34;https://arxiv.org/abs/2302.10866&#34;&gt;&lt;em&gt;Poli et al. (2023)&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;算是初步学习机器学习相关的知识，此前只听过些专有名词。&lt;/p&gt;
&lt;p&gt;但是之前就看过一些向量数据库和知识图片的文章，在看上述两篇文章之前，我就认为可以使用到类似概念的数据库来存储，&lt;/p&gt;
&lt;p&gt;“应该是修改某一部分的 “记忆”，使完成本次对话的时候，能够可能访问到该此更新。而不是携带前 n 次的 qa。”&lt;/p&gt;
&lt;p&gt;“记忆也应该有多层。”&lt;/p&gt;
&lt;p&gt;今天也看了 GLM 的&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3ZpZGVvL0JWMWI2NDIxdTc0RS8/c2hhcmVfc291cmNlPWNvcHlfd2ViJmFtcDt2ZF9zb3VyY2U9ZmYyY2QxYmIyMDc2NmE2OTE5ZTJhZmM3ZmEzNjM2YTM=&#34;&gt; 2024，智能体 Builder 时代，来临了吗？&lt;/span&gt;，初步了解了大模型的架构&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;image-20240211194517900.png&#34; alt=&#34;image-20240211194517900&#34; /&gt;&lt;/p&gt;
</content>
        <category term="GLM" />
        <updated>2024-02-11T11:26:02.000Z</updated>
    </entry>
</feed>
